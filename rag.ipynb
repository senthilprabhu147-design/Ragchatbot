{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b7a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: SET\n",
      "GOOGLE_API_KEY: SET\n",
      "GOOGLE_APPLICATION_CREDENTIALS: NOT SET\n",
      "Some required env vars are missing. Copy .env.example -> .env and fill them.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env (do not commit secrets)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "required = [\"OPENAI_API_KEY\", \"GOOGLE_API_KEY\", \"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "missing = []\n",
    "for k in required:\n",
    "    v = os.environ.get(k)\n",
    "    status = 'SET' if v else 'NOT SET'\n",
    "    print(f\"{k}: {status}\")\n",
    "    if not v:\n",
    "        missing.append(k)\n",
    "\n",
    "if missing:\n",
    "    print(\"Some required env vars are missing. Copy .env.example -> .env and fill them.\")\n",
    "else:\n",
    "    print(\"All required env vars are present (values hidden).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be11f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: d:\\langchainrAG\n",
      ".env path: d:\\langchainrAG\\.env\n",
      ".env exists: True\n",
      "find_dotenv returned: d:\\langchainrAG\\.env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv\n",
    "print('cwd:', os.getcwd())\n",
    "print('.env path:', os.path.abspath('.env'))\n",
    "print('.env exists:', os.path.exists('.env'))\n",
    "print('find_dotenv returned:', find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8efc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_dotenv returned: d:\\langchainrAG\\.env\n",
      "load_dotenv returned: True\n",
      "OPENAI_API_KEY SET\n",
      "GOOGLE_API_KEY SET\n",
      "GOOGLE_APPLICATION_CREDENTIALS NOT SET\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "p = find_dotenv()\n",
    "print('find_dotenv returned:', p)\n",
    "loaded = load_dotenv(p, override=True)\n",
    "print('load_dotenv returned:', loaded)\n",
    "for k in ['OPENAI_API_KEY', 'GOOGLE_API_KEY', 'GOOGLE_APPLICATION_CREDENTIALS']:\n",
    "    print(k, 'SET' if os.getenv(k) else 'NOT SET')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857e6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcec4345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d994974",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "gemini_key = google_api_key or os.getenv(\"GEMINI_API_KEY\")\n",
    "if gemini_key:\n",
    "    google_llm = ChatGoogleGenerativeAI(\n",
    "        temperature=0,\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        api_key=gemini_key,\n",
    "        max_tokens=200\n",
    "    )\n",
    "elif os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"):\n",
    "    # Use ADC (Application Default Credentials)\n",
    "    google_llm = ChatGoogleGenerativeAI(\n",
    "        temperature=0,\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        max_tokens=200\n",
    "    )\n",
    "else:\n",
    "    google_llm = None\n",
    "    print(\"Warning: No Gemini credentials found (GOOGLE_API_KEY/GEMINI_API_KEY/GOOGLE_APPLICATION_CREDENTIALS). google_llm not created.\")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4\", \n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbde86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai_llm: ChatOpenAI\n",
      "google_llm: ChatGoogleGenerativeAI\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check that the LLM objects were created\n",
    "print('openai_llm:', type(openai_llm).__name__ if 'openai_llm' in globals() else 'NOT CREATED')\n",
    "print('google_llm:', type(google_llm).__name__ if 'google_llm' in globals() and google_llm is not None else 'NOT CREATED or None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e550757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'tool' import removed (not available in this langchain version)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader_1 = PyPDFLoader(\n",
    "    r\"D:\\langchainrAG\\facebook-guide.pdf\",\n",
    ")\n",
    "\n",
    "pdf_loader_2 = PyPDFLoader(\n",
    "    r\"D:\\langchainrAG\\gzip.pdf\",\n",
    ")\n",
    "\n",
    "text_loader = TextLoader(\n",
    "    r\"D:\\langchainrAG\\coolie_english.txt\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "pdf_1_docs = pdf_loader_1.load()\n",
    "pdf_2_docs = pdf_loader_2.load()\n",
    "# Load text file with utf-8, fall back to latin-1 if necessary\n",
    "text_docs = text_loader.load()\n",
    "\n",
    "all_docs = pdf_1_docs + pdf_2_docs + text_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0b86bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "29\n",
      "1\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "print(len(pdf_1_docs))\n",
    "print(len(pdf_2_docs))\n",
    "print(len(text_docs))\n",
    "\n",
    "print(len(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f97bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cccab8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d165ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senth\\AppData\\Local\\Temp\\ipykernel_24828\\3497288736.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.from_documents(split_docs, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afc3216b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated triple-quoted string literal (detected at line 57) (1936940894.py, line 46)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"),\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated triple-quoted string literal (detected at line 57)\n"
     ]
    }
   ],
   "source": [
    "results = await vectorstore.asimilarity_search(\"who is dahaa in coolie?\")\n",
    "code\n",
    "#VSC-c24f24bd\n",
    "python\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\", \"\"\"Always answer the question just by using the context provided and not from your knowledge.\n",
    ",\n",
    "     (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = {\"context\": retriever, \"input\": RunnablePassthrough()} | prompt | google_llm\n",
    "\n",
    "# chain = {\"context\": RunnableLambda(lambda x: x[\"input\"]) | retriever, \"input\": RunnableLambda(lambda x: x[\"input\"])} | prompt | google_llm | StrOutputParser()\n",
    "\n",
    "try:\n",
    "    res = chain.invoke(\"What is gzip?\")\n",
    "except Exception as e:\n",
    "    print(\"Primary Google LLM failed:\", e)\n",
    "    if 'openai_llm' in globals() and openai_llm is not None:\n",
    "        print(\"Falling back to OpenAI LLM\")\n",
    "        chain2 = {\"context\": retriever, \"input\": RunnablePassthrough()} | prompt | openai_llm\n",
    "        try:\n",
    "            res = chain2.invoke(\"What is gzip?\")\n",
    "        except Exception as e2:\n",
    "            print(\"Fallback OpenAI failed:\", e2)\n",
    "            res = f\"Both LLM calls failed: {e2}\"\n",
    "    else:\n",
    "        res = f\"Google LLM failed and no OpenAI LLM available: {e}\"\n",
    "\n",
    "res\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\", \"\"\"Always answer the question just by using the context provided and not from your knowledge.\n",
    "        Context: {context}\n",
    "        question: {input}\n",
    "     \n",
    "        Answer: \n",
    "     \"\"\"),\n",
    "     (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = {\"context\": retriever, \"input\": RunnablePassthrough()} | prompt | google_llm\n",
    "\n",
    "# chain = {\"context\": RunnableLambda(lambda x: x[\"input\"]) | retriever, \"input\": RunnableLambda(lambda x: x[\"input\"])} | prompt | google_llm | StrOutputParser()\n",
    "\n",
    "res = chain.invoke(\"What is gzip?\")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafb643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
